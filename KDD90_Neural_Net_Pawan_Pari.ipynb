{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02533c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NET\n",
    "# Pawan Harikrishnan & Parinita Mithepati "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86763d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.7.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pawan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\pawan\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# STEP 0 - Install pytorch and its dependencies\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db99e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9447ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 - Import the training and test files for the dataset \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "# training data import\n",
    "training_data = pd.read_csv('train_kdd_small.csv')\n",
    "# testing data import\n",
    "testing_data = pd.read_csv('test_kdd_small.csv')\n",
    "# testing and training data do not have the same the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d0ed06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the files to make sure theyre being imported correctly \n",
    "#print(training_data)\n",
    "#print(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aef3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 - Dataset needs to be modified as not all the columns have numbers as data type \n",
    "# Protocol Type - icmp, tcp \n",
    "# Service - ecr_i, http \n",
    "# Flag - SF\n",
    "# Label - not_normal, normal \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# create the label encoder \n",
    "encoder_string_converted_label = LabelEncoder()\n",
    "\n",
    "# 1.) encode protocol type where icmp = 0, tcp = 1\n",
    "encoder_string_converted_label.fit(training_data['protocol_type'])\n",
    "# map to the testing and training data\n",
    "training_data['protocol_type'] = encoder_string_converted_label.transform(training_data['protocol_type'])\n",
    "testing_data['protocol_type'] = encoder_string_converted_label.transform(testing_data['protocol_type'])\n",
    "# check the data to make sure its getting converted \n",
    "#print(training_data['protocol_type'])\n",
    "#print(testing_data['protocol_type'])\n",
    "\n",
    "# 2.) encode servicve type where ecr_i = 0, http = 1\n",
    "encoder_string_converted_label.fit(training_data['service'])\n",
    "# map to the testing and training data\n",
    "training_data['service'] = encoder_string_converted_label.transform(training_data['service'])\n",
    "testing_data['service'] = encoder_string_converted_label.transform(testing_data['service'])\n",
    "# check the data to make sure its getting converted \n",
    "#print(training_data['service'])\n",
    "#print(testing_data['service'])\n",
    "\n",
    "# 3.) encode flag type where SF=0\n",
    "encoder_string_converted_label.fit(training_data['flag'])\n",
    "# map to the testing and training data\n",
    "training_data['flag'] = encoder_string_converted_label.transform(training_data['flag'])\n",
    "testing_data['flag'] = encoder_string_converted_label.transform(testing_data['flag'])\n",
    "# check the data to make sure its getting converted \n",
    "#print(training_data['flag'])\n",
    "#print(testing_data['flag'])\n",
    "\n",
    "\n",
    "# 4.) encode label type where not_normal = 0, http = 1\n",
    "encoder_string_converted_label.fit(training_data['label'])\n",
    "# map to the testing and training data\n",
    "training_data['label'] = encoder_string_converted_label.transform(training_data['label'])\n",
    "testing_data['label'] = encoder_string_converted_label.transform(testing_data['label'])\n",
    "# check the data to make sure its getting converted \n",
    "#print(training_data['label'])\n",
    "#print(testing_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feac1b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - The model now needs to be trained using the training set without the labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NEW TRAINING FILE\n",
    "x_training_dropped = training_data.drop('label',axis=1)\n",
    "y_training_final = training_data['label']\n",
    "# check to make sure it dropped the last column\n",
    "#print(x_training_final.shape)\n",
    "#print(x_training_final.head())\n",
    "#print(y_training_final.head())\n",
    "\n",
    "# NEW TESTING FILE\n",
    "x_testing_dropped = testing_data.drop('label',axis=1)\n",
    "y_testing_final = testing_data['label']\n",
    "# check to make sure it dropped the last column\n",
    "#print(x_testing_final.shape)\n",
    "#print(x_testing_final.head())\n",
    "#print(y_testing_final.head())\n",
    "\n",
    "# VALIDATION SETS\n",
    "x_training_set, x_validation_set, y_training_set, y_validation_set = train_test_split(x_training_dropped, y_training_final,test_size=0.20,random_state=1,stratify=y_training_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cffef078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 (OPTIMIZATION STEP) \n",
    "# currently the model is too good, so its probably running into overfitting issues \n",
    "# this is the model output with no optimization steps\n",
    "\n",
    "# MODEL OUTPUT\n",
    "# Model Accuracy : % 100.0\n",
    "# Model Precision: % 100.0\n",
    "# Model Recall   : % 100.0\n",
    "# Model F1 Score : % 100.0\n",
    "\n",
    "# 1.) add the l2 regularzation penalty  \n",
    "\n",
    "# 2.) choose a really low value for C \n",
    "\n",
    "# 3.) add noice to the training data  (skipping for now)\n",
    "\n",
    "# 4.) normalize the data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create the scalar first\n",
    "scaler_logistic_regression = StandardScaler()\n",
    "\n",
    "\n",
    "# normalize x_training_final and x_testing_final from the last step so some features are not too skewed, need to do fit_transform first or it;ll throw an error\n",
    "x_training_normalized = scaler_logistic_regression.fit_transform(x_training_set)\n",
    "x_validation_normalized = scaler_logistic_regression.transform(x_validation_set)\n",
    "x_testing_normalized  = scaler_logistic_regression.transform(x_testing_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5 - Create the neural net class now \n",
    "# use the neural net module \n",
    "class NeuralNetKDD90(nn.module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # super for the main model class\n",
    "        super(NeuralNetKDD90,self).__init__()\n",
    "        \n",
    "        # inputs -> hidden layers + the function to add the bias -> outputs \n",
    "        \n",
    "        # incoming inputs need to get mapped to the first set of hidden layers \n",
    "        self.fc1 = nn.Linear(input_size,hidden_size)\n",
    "        # from these layers the get mapped to the outputs \n",
    "        self.fc2 = nn.Linear(hidden_size,output_size)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
